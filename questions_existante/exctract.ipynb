{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Connexion a Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"token_hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exctracction des questions et reponses du document dans un fichier JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_text_from_docx(docx_path,output_txt=\"test.txt\"):\n",
    "    \"\"\"Extrait le texte brut d'un fichier Word.\"\"\"\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    return text\n",
    "def extract_text_from_pdf_no_out(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "\n",
    "    return text\n",
    "    \n",
    "    return text\n",
    "def parse_questions(text):\n",
    "    \"\"\"Parse uniquement les questions et options √† partir du texte extrait.\"\"\"\n",
    "    questions = []\n",
    "    question_blocks = re.split(r'Question \\d+', text)\n",
    "    \n",
    "    \n",
    "    with open(\"test_block.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n=== Nouveau Bloc ===\\n\\n\".join(question_blocks))  \n",
    "    \n",
    "    for block in question_blocks[1:]:  # On saute la premi√®re partie (avant la premi√®re question)\n",
    "        lines = block.strip().split('\\n')\n",
    "        question_text_lines = []\n",
    "        options = {}\n",
    "        current_option = None\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if \"Answer\" in line:\n",
    "                break  # Arr√™ter l'ajout de texte d√®s qu'on atteint \"Answer\"\n",
    "            \n",
    "            # D√©tecter une option (A., B., C., D.)\n",
    "            match_option = re.match(r'([A-E])\\.\\s*(.*)', line)\n",
    "            \n",
    "            if match_option:\n",
    "                current_option = match_option.group(1)\n",
    "                options[current_option] = match_option.group(2).strip()\n",
    "            elif current_option:\n",
    "                options[current_option] += \" \" + line  # Ajouter le texte multi-ligne des options\n",
    "            else:\n",
    "                question_text_lines.append(line)\n",
    "                \n",
    "        question_text = ' '.join(question_text_lines).strip()\n",
    "        \n",
    "        if question_text and options:\n",
    "            questions.append({\n",
    "                \"QuestionText\": question_text,\n",
    "                \"Options\": options\n",
    "            })\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_answers(text):\n",
    "    \"\"\"Parse uniquement les r√©ponses correctes et explications √† partir du texte extrait.\"\"\"\n",
    "    answers = []\n",
    "    answer_blocks = re.split(r'Answer', text)[1:]  # Diviser apr√®s chaque 'Answer'\n",
    "    \n",
    "    with open(\"answer_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n=== Nouveau Bloc ===\\n\\n\".join(answer_blocks))  \n",
    "    \n",
    "    for block in answer_blocks:\n",
    "        lines = block.strip().split('\\n')\n",
    "        correct_answer = \"\"\n",
    "        explanation_lines = []\n",
    "        found_answer = False  # Pour savoir quand commencer √† stocker l'explication\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # D√©tection am√©lior√©e de la r√©ponse correcte\n",
    "            answer_match = re.search(r'The correct\\s*answer\\s*is\\s*([A-E])', line, re.IGNORECASE)\n",
    "            if answer_match:\n",
    "                correct_answer = answer_match.group(1)\n",
    "                found_answer = True  # D√©but de l'explication\n",
    "                continue  # Passer √† la ligne suivante directement\n",
    "            \n",
    "            # Ajout de l'explication (sans stopper trop t√¥t)\n",
    "            if found_answer:\n",
    "                explanation_lines.append(line)\n",
    "        \n",
    "        # Enregistrement de la r√©ponse\n",
    "        if correct_answer:\n",
    "            answers.append({\n",
    "                \"CorrectAnswer\": correct_answer,\n",
    "                \"Explanation\": ' '.join(explanation_lines).strip()\n",
    "            })\n",
    "    \n",
    "    return answers\n",
    "\n",
    "def combine_questions_and_answers(questions, answers):\n",
    "    \"\"\"Combine les questions et r√©ponses en une seule structure JSON avec le num√©ro de question.\"\"\"\n",
    "    combined = []\n",
    "    for i, (q, a) in enumerate(zip(questions, answers), start=1):  # D√©marre √† 1\n",
    "        combined.append({\n",
    "            \"QuestionNumber\": i,  # üî• Ajout du num√©ro de la question\n",
    "            \"QuestionText\": q[\"QuestionText\"],\n",
    "            \"Options\": q[\"Options\"],\n",
    "            \"CorrectAnswer\": a[\"CorrectAnswer\"],\n",
    "            \"Explanation\": a[\"Explanation\"],\n",
    "            \"Question_type\": \"MCQ\",\n",
    "            \"file\":\"Questions Sup OEB\"\n",
    "        })\n",
    "    return combined\n",
    "\n",
    "def save_to_json(data, output_path):\n",
    "    \"\"\"Ajoute les nouvelles donn√©es au fichier JSON existant sans l'√©craser.\"\"\"\n",
    "    try:\n",
    "        with open(output_path, 'r', encoding='utf-8') as f:\n",
    "            existing_data = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        existing_data = []\n",
    "    \n",
    "    existing_data.extend(data)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(existing_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Donn√©es ajout√©es √† {output_path}\")\n",
    "\n",
    "# Chemin du fichier Word\n",
    "input_docx_path = \"exam/Questions Sup OEB.docx\"\n",
    "output_json_path = \"questions_and_answers.json\"\n",
    "\n",
    "# Ex√©cuter le traitement\n",
    "text = extract_text_from_pdf_no_out(\"test.txt\")\n",
    "questions_data = parse_questions(text)\n",
    "answers_data = parse_answers(text)\n",
    "combined_data = combine_questions_and_answers(questions_data, answers_data)\n",
    "save_to_json(combined_data, output_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignation des cat√©gories pour chaque question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import docx\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def assign_questions_to_categories(questions_json, categories_docx, output_json):\n",
    "    # Charger les questions\n",
    "    with open(questions_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        questions_data = json.load(f)\n",
    "    \n",
    "    # Charger les cat√©gories depuis le fichier DOCX\n",
    "    def load_categories(docx_path):\n",
    "        doc = docx.Document(docx_path)\n",
    "        categories = []\n",
    "        current_category = None\n",
    "        \n",
    "        for para in doc.paragraphs:\n",
    "            text = para.text.strip()\n",
    "            if text and text[0].isdigit():  # Identifier une nouvelle cat√©gorie\n",
    "                current_category = text\n",
    "            elif text and current_category:\n",
    "                categories.append({\"category\": current_category, \"description\": text})\n",
    "        \n",
    "        return categories\n",
    "    \n",
    "    categories = load_categories(categories_docx)\n",
    "    \n",
    "    # Pr√©parer les textes des cat√©gories et questions\n",
    "    category_texts = [cat[\"description\"] for cat in categories]\n",
    "    question_texts = [q[\"QuestionText\"] for q in questions_data]\n",
    "    \n",
    "    # Transformer en vecteurs TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(category_texts + question_texts)\n",
    "    \n",
    "    # S√©parer les vecteurs cat√©gories et questions\n",
    "    category_vectors = tfidf_matrix[: len(categories)]\n",
    "    question_vectors = tfidf_matrix[len(categories) :]\n",
    "    \n",
    "    # Calculer la similarit√© cosinus\n",
    "    similarity_matrix = cosine_similarity(question_vectors, category_vectors)\n",
    "    \n",
    "    # Assigner chaque question √† la cat√©gorie la plus proche\n",
    "    for i, question in enumerate(questions_data):\n",
    "        best_match_index = np.argmax(similarity_matrix[i])\n",
    "        best_category = categories[best_match_index][\"category\"]\n",
    "        question[\"Theme\"] = best_category  # Ajout du th√®me dans la question\n",
    "    \n",
    "    # Sauvegarder les r√©sultats avec les th√®mes ajout√©s\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(questions_data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Fichier mis √† jour avec les th√®mes : {output_json}\")\n",
    "    \n",
    "\n",
    "cat=\"Categories.docx\"\n",
    "question=\"fichier_questions.json\"\n",
    "output=\"output.json\"\n",
    "assign_questions_to_categories(question,cat,output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supression des nombres pour insertion dans base de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def remove_numbers_from_theme(json_file, output_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    def clean_theme(theme):\n",
    "        return re.sub(r'^\\d+(\\.\\d+)*\\s*', '', theme)\n",
    "    \n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if \"Theme\" in item:\n",
    "                item[\"Theme\"] = clean_theme(item[\"Theme\"])\n",
    "    elif isinstance(data, dict) and \"Theme\" in data:\n",
    "        data[\"Theme\"] = clean_theme(data[\"Theme\"])\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "input_file = \"fichier.json\"\n",
    "output_file = \"fichier.json\"\n",
    "remove_numbers_from_theme(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertion des questions dans base de donn√©es firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def ajouter_questions_firestore(chemin_fichier_json, nom_collection):\n",
    "    \"\"\"\n",
    "    Lit les donn√©es d'un fichier JSON et les ajoute √† une collection Firestore.\n",
    "\n",
    "    Args:\n",
    "        chemin_fichier_json (str): Chemin vers le fichier JSON contenant les donn√©es.\n",
    "        nom_collection (str): Nom de la collection Firestore.\n",
    "    \"\"\"\n",
    "        # V√©rifier si Firebase est d√©j√† initialis√©\n",
    "    if not firebase_admin._apps:\n",
    "        cred = credentials.Certificate(\"fichier_firebase.json\")\n",
    "        firebase_admin.initialize_app(cred)\n",
    "\n",
    "    # Connexion √† Firestore\n",
    "    db = firestore.client()\n",
    "    \n",
    "    try:\n",
    "        with open(chemin_fichier_json, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # V√©rifie que le JSON est bien une liste de dictionnaires\n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError(\"Le fichier JSON doit contenir une liste d'objets.\")\n",
    "\n",
    "        collection_ref = db.collection(nom_collection)\n",
    "\n",
    "        for question in data:\n",
    "            if not isinstance(question, dict):\n",
    "                print(f\"‚ö†Ô∏è Erreur : Un √©l√©ment du JSON n'est pas un dictionnaire : {question}\")\n",
    "                continue  # Ignore les mauvais formats\n",
    "            \n",
    "            # Ajoute chaque question comme un document unique dans Firestore\n",
    "            doc_ref = collection_ref.document(f\"{question['QuestionNumber']}_{question['file']}\")  # Utilisation du num√©ro de question comme ID\n",
    "            doc_ref.set(question)\n",
    "\n",
    "        print(f\"‚úÖ Donn√©es ajout√©es avec succ√®s √† Firestore dans '{nom_collection}'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Erreur : Le fichier '{chemin_fichier_json}' est introuvable.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"‚ùå Erreur : Le fichier '{chemin_fichier_json}' n'est pas un JSON valide.\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"‚ùå Erreur de format JSON : {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Une erreur s'est produite : {e}\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "chemin_fichier_json = 'fichier.json'\n",
    "nom_collection = 'qcm'\n",
    "\n",
    "ajouter_questions_firestore(chemin_fichier_json, nom_collection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertion des th√®mes dans base de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "import json\n",
    "\n",
    "# V√©rifier si Firebase est d√©j√† initialis√©\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(\"fichier_firebase.json\")\n",
    "    firebase_admin.initialize_app(cred)\n",
    "\n",
    "# Connexion √† Firestore\n",
    "db = firestore.client()\n",
    "\n",
    "def ajouter_themes_firestore(json_data, nom_collection):\n",
    "    \"\"\"\n",
    "    Envoie les th√®mes et sous-th√®mes dans Firestore.\n",
    "\n",
    "    Args:\n",
    "        json_data (dict): Donn√©es JSON √† envoyer.\n",
    "        nom_collection (str): Nom de la collection Firestore.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        collection_ref = db.collection(nom_collection)\n",
    "\n",
    "        for theme, sous_themes in json_data.items():\n",
    "            doc_id = theme.replace(' ', '_')\n",
    "            doc_ref = collection_ref.document(doc_id)\n",
    "\n",
    "            # Pr√©parer la structure avec les sous-th√®mes sous forme de liste\n",
    "            theme_data = {\n",
    "                \"theme\": theme,\n",
    "                \"sous_themes\": [\n",
    "                    {\"nom\": sous_theme, \"description\": description}\n",
    "                    for sous_theme, description in sous_themes.items()\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Cr√©er un document unique pour chaque th√®me principal\n",
    "            doc_ref.set(theme_data)\n",
    "\n",
    "        print(f\"‚úÖ Donn√©es ajout√©es avec succ√®s √† Firestore dans '{nom_collection}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Une erreur s'est produite : {e}\")\n",
    "\n",
    "# Charger les donn√©es JSON depuis le fichier\n",
    "chemin_fichier_json = 'themes.json'\n",
    "nom_collection = 'themes'\n",
    "\n",
    "try:\n",
    "    with open(chemin_fichier_json, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    ajouter_themes_firestore(data, nom_collection)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Erreur : Le fichier '{chemin_fichier_json}' est introuvable.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"‚ùå Erreur : Le fichier '{chemin_fichier_json}' n'est pas un JSON valide.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
